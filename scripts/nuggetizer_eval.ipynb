{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23133077-d081-424e-aeb8-2f95eaf026af",
   "metadata": {},
   "source": [
    "# Nuggets creation and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726e458-a3d0-45ca-b84b-2d378a4fcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_rag.backend import OpenAIBackend\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"casperhansen/llama-3.3-70b-instruct-awq\")\n",
    "\n",
    "generation_args={\n",
    "    \"temperature\": 0.6,\n",
    "    \"max_tokens\": 256,\n",
    "}\n",
    "\n",
    "# this could equally be a real OpenAI models\n",
    "llama = OpenAIBackend(model_name, \n",
    "                      api_key=os.environ['IDA_LLM_API_KEY'],\n",
    "                      generation_args=generation_args,\n",
    "                      base_url=\"http://api.llm.apps.os.dcs.gla.ac.uk/v1\", \n",
    "                      verbose=True, \n",
    "                      parallel=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4c501-ba83-43ce-9688-b23c5b1b1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastchat.conversation import get_conv_template\n",
    "from open_nuggetizer.nuggetizer import Nuggetizer\n",
    "\n",
    "conv_template = get_conv_template(\"meta-llama-3.1-sp\")\n",
    "\n",
    "nuggetizer = Nuggetizer(\n",
    "    backend=backend, \n",
    "    conversation_template=conv_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "nuggets = load_csv(\"nuggets.csv\")\n",
    "if nuggets is None:\n",
    "    nuggets = nuggetizer.create(baseline)\n",
    "    save_csv(\"nuggets.csv\", nuggets)\n",
    "\n",
    "scored_nuggets = load_csv(\"scored_nuggets.csv\")\n",
    "if scored_nuggets is None:\n",
    "    scored_nuggets = nuggetizer.score(nuggets)\n",
    "    save_csv(\"scored_nuggets.csv\", scored_nuggets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c067f-36ae-436f-874f-c31711fe40c1",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd6a23-4c43-4720-a4fe-9512a3928a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_rag.prompt import Concatenator\n",
    "from pyterrier_rag.readers import Reader\n",
    "from pyterrier_rag.prompt import PromptTransformer\n",
    "from jinja2 import Template\n",
    "\n",
    "def make_callable_template(template: Template):\n",
    "    def template_call(**kwargs):\n",
    "        return template.render(**kwargs)\n",
    "\n",
    "    return template_call\n",
    "\n",
    "GENERIC_PROMPT = Template(\n",
    "    \"Use the context information to answer the Question: \\n Context: {{ context }} \\n Question: {{ query }} \\n Answer:\"\n",
    ")\n",
    "\n",
    "prompt = PromptTransformer(\n",
    "            instruction=make_callable_template(GENERIC_PROMPT),\n",
    "            system_message=\"You are an helpful assistant.\",\n",
    "            conversation_template=conv_template,\n",
    "            input_fields=[\n",
    "                \"qcontext\",\n",
    "                \"query\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "reader = Reader(backend, prompt)\n",
    "rag_pipeline = monoT5_ret % 3 >> Concatenator() >> reader\n",
    "\n",
    "results = (rag_pipeline)(topics_df.head(2))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d3533-dfda-434f-8cd2-f9106b9517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_nuggets = scored_nuggets.rename(columns={\"query_id\": \"qid\"})\n",
    "results = results.rename(columns={\"query_id\": \"qid\", \"query_0\": \"query\"})\n",
    "for element in nuggetizer.VitalScore().iter_calc(scored_nuggets, results):\n",
    "    print(f\"Query ID: {element.query_id}, Measure: {element.measure}, Value: {element.value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptrag]",
   "language": "python",
   "name": "conda-env-ptrag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
